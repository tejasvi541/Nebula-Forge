"""
NEBULA-FORGE — Provisioner
All file/folder creation logic with Ghost Provisioning (diff preview).
"""

from __future__ import annotations
import json
import shutil
from datetime import datetime
from pathlib import Path
from typing import Callable, Optional

from .models import (
    AgentConfig,
    ProjectContext,
    ProvisionEntry,
    ProvisionPlan,
    SkillMetadata,
)
from .vault import Vault


SKILL_MD_TEMPLATE = """\
---
name: {name}
category: {category}
version: {version}
author: {author}
model_preference: {model_preference}
thinking_mode: auto
created_at: {created_at}
tags: {tags}
description: >
  {description}
---

# Skill: {name}

## Purpose
{description}

## When to Use This Skill
<!-- Describe the scenarios where an agent should invoke this skill -->

## Instructions

### Context
<!-- What context does the agent need to execute this skill effectively? -->

### Steps
1. <!-- Step 1 -->
2. <!-- Step 2 -->
3. <!-- Step 3 -->

### Output Format
<!-- Describe the expected output format -->

## Examples

### Input
```
<!-- Example input/trigger for this skill -->
```

### Output
```
<!-- Example output when skill executes -->
```

## Model Notes
- **Preferred Model:** `{model_preference}`
- **Thinking Mode:** `auto` — set to `ultra` for complex reasoning tasks
- **Context Requirement:** Medium — adjust based on task complexity

## Constraints
- <!-- Constraint 1 -->
- <!-- Constraint 2 -->

## Related Skills
- <!-- Link to related skill -->
"""

CLAUDE_MD_TEMPLATE = """\
# CLAUDE.md — Project Memory Bank
# Generated by NEBULA-FORGE · {timestamp}
# Optimized for Claude Opus 4.6 extended context window

## Project Identity

**Name:** {project_name}
**Path:** {project_path}
**Stack:** {stack}

## Architecture Overview

<!-- Describe the high-level architecture here -->

## Key Design Decisions

<!-- List ADRs (Architecture Decision Records) here -->
- ADR-001: <!-- Decision title -->

## Code Conventions

### Naming
- <!-- Naming convention 1 -->

### Patterns
- <!-- Pattern 1 -->

### Anti-Patterns (DO NOT DO)
- <!-- Anti-pattern 1 -->

## Active Context

### Current Sprint Goal
<!-- What are we building right now? -->

### In Progress
- [ ] <!-- Task 1 -->

### Blocked By
- <!-- Blocker -->

## Domain Knowledge

<!-- Critical domain concepts the agent must understand -->

## File Map

```
{project_name}/
├── <!-- key directory 1 -->  # purpose
├── <!-- key directory 2 -->  # purpose
└── <!-- key directory 3 -->  # purpose
```

## External Dependencies

| Service | Purpose | Docs |
|---------|---------|------|
| <!-- service --> | <!-- purpose --> | <!-- url --> |

## Skill Injections

<!-- Skills active in this project context -->
{skill_injections}

## Agent Instructions

When working on this project:
1. Always read this file first for context
2. Check `.nebula/agents/` for active agent configurations
3. Use `[thinking_mode: ultra]` for architecture decisions
4. Use `[model_context: high_effort]` for complex refactors
5. Commit changes with conventional commit format

## Changelog

| Date | Change | Author |
|------|--------|--------|
| {timestamp} | Initial CLAUDE.md generated | nebula-forge |
"""

GEMINI_CONFIG_TEMPLATE = """\
{{
  "model": "gemini-3.1-pro-preview",
  "generation_config": {{
    "temperature": 0.2,
    "top_p": 0.95,
    "max_output_tokens": 65536,
    "thinking_config": {{
      "thinking_budget": 32768,
      "include_thoughts": true
    }}
  }},
  "system_instruction": "You are a senior software engineer working on {project_name}. Read CLAUDE.md for full project context before every task.",
  "tools": [
    {{
      "function_declarations": [
        {{
          "name": "read_file",
          "description": "Read the contents of a file",
          "parameters": {{
            "type": "object",
            "properties": {{
              "path": {{ "type": "string", "description": "File path relative to project root" }}
            }},
            "required": ["path"]
          }}
        }},
        {{
          "name": "write_file",
          "description": "Write content to a file",
          "parameters": {{
            "type": "object",
            "properties": {{
              "path": {{ "type": "string" }},
              "content": {{ "type": "string" }}
            }},
            "required": ["path", "content"]
          }}
        }},
        {{
          "name": "run_command",
          "description": "Execute a shell command",
          "parameters": {{
            "type": "object",
            "properties": {{
              "command": {{ "type": "string" }},
              "cwd": {{ "type": "string" }}
            }},
            "required": ["command"]
          }}
        }}
      ]
    }}
  ],
  "project": {{
    "name": "{project_name}",
    "path": "{project_path}",
    "memory_bank": "CLAUDE.md",
    "agent_config_dir": ".nebula/agents/"
  }}
}}"""


# ── OpenCode-first Templates ──────────────────────────────────────────────────

AGENTS_MD_TEMPLATE = """\
# AGENTS.md — Project Rules & Memory Bank
# Generated by NEBULA-FORGE · {timestamp}
# Compatible with OpenCode, Claude Code, and all modern AI coding agents

## Project Identity

**Name:** {project_name}
**Path:** {project_path}
**Stack:** {stack}

## Architecture Overview

<!-- Describe the high-level architecture here -->

## Key Design Decisions

<!-- List ADRs (Architecture Decision Records) here -->
- ADR-001: <!-- Decision title -->

## Code Conventions

### Naming
- <!-- Naming convention 1 -->

### Patterns
- <!-- Pattern 1 -->

### Anti-Patterns (DO NOT DO)
- <!-- Anti-pattern 1 -->

## Active Context

### Current Sprint Goal
<!-- What are we building right now? -->

### In Progress
- [ ] <!-- Task 1 -->

### Blocked By
- <!-- Blocker -->

## Domain Knowledge

<!-- Critical domain concepts the agent must understand -->

## File Map

```
{project_name}/
├── <!-- key directory 1 -->  # purpose
├── <!-- key directory 2 -->  # purpose
└── <!-- key directory 3 -->  # purpose
```

## External Dependencies

| Service | Purpose | Docs |
|---------|---------|------|
| <!-- service --> | <!-- purpose --> | <!-- url --> |

## Skill Injections

{skill_injections}

## Agent Instructions

When working on this project:
1. Always read AGENTS.md first for full project context
2. Check `.opencode/agents/` for active agent configurations
3. Use `[thinking_mode: ultra]` for architecture decisions
4. Use `[model_context: high_effort]` for complex refactors
5. Commit changes with conventional commit format

## Changelog

| Date | Change | Author |
|------|--------|--------|
| {timestamp} | Initial AGENTS.md generated | nebula-forge |
"""

OPENCODE_JSON_TEMPLATE = """\
{
  "$schema": "https://opencode.ai/config.json",
  "model": "copilot/claude-opus-4-6",
  "autoshare": false,
  "share": "manual",
  "provider": {},
  "keybinds": {},
  "mcp": {}
}"""


class Provisioner:
    """
    Handles all file system operations for NEBULA-FORGE.
    Always builds a ProvisionPlan (ghost diff) before writing.
    """

    def __init__(self, vault: Vault) -> None:
        self.vault = vault

    # ── Skill Factory ────────────────────────────────────────

    def plan_skill_creation(self, meta: SkillMetadata, target_dir: Path | None = None) -> ProvisionPlan:
        base = target_dir if target_dir is not None else self.vault.skills_dir
        skill_dir = base / meta.name
        skill_md = skill_dir / "SKILL.md"

        content = SKILL_MD_TEMPLATE.format(
            name=meta.name,
            category=meta.category,
            version=meta.version,
            author=meta.author,
            model_preference=meta.model_preference,
            created_at=meta.created_at,
            tags=", ".join(meta.tags) if meta.tags else "general",
            description=meta.description,
        )

        entries = [
            ProvisionEntry(
                path=str(skill_dir),
                content="",
                action="create",
                description=f"Skill directory: {meta.name}/",
            ),
            ProvisionEntry(
                path=str(skill_md),
                content=content,
                action="create",
                description="SKILL.md with 2026-standard YAML frontmatter",
            ),
        ]

        scope_label = str(target_dir) if target_dir else str(self.vault.skills_dir)
        return ProvisionPlan(
            title=f"Create Skill: {meta.name}",
            entries=entries,
            total_files=1,
            total_dirs=1,
            description=f"Provision skill '{meta.name}' in {scope_label}",
        )

    def execute_skill_creation(
        self,
        plan: ProvisionPlan,
        on_progress: Optional[Callable[[str, float], None]] = None,
    ) -> bool:
        try:
            total = len(plan.entries)
            for i, entry in enumerate(plan.entries):
                p = Path(entry.path)
                if entry.action == "create":
                    if p.suffix:  # it's a file
                        p.parent.mkdir(parents=True, exist_ok=True)
                        p.write_text(entry.content, encoding="utf-8")
                    else:
                        p.mkdir(parents=True, exist_ok=True)
                if on_progress:
                    on_progress(entry.description, (i + 1) / total)
            return True
        except Exception as e:
            return False

    def copy_skill_to_project(
        self, skill_name: str, project_path: Path
    ) -> ProvisionPlan:
        src = self.vault.skills_dir / skill_name
        skills_subdir = self.vault.load().project_skills_subdir
        dst_dir = project_path / skills_subdir / skill_name
        dst_file = dst_dir / "SKILL.md"
        src_file = src / "SKILL.md"

        content = src_file.read_text() if src_file.exists() else "# Skill copied"

        return ProvisionPlan(
            title=f"Copy Skill '{skill_name}' → Project",
            entries=[
                ProvisionEntry(path=str(dst_dir), content="", action="create"),
                ProvisionEntry(
                    path=str(dst_file),
                    content=content,
                    action="create",
                    description=f"Copy {skill_name}/SKILL.md → {skills_subdir}/{skill_name}/",
                ),
            ],
            total_files=1,
            total_dirs=1,
            project_path=str(project_path),
        )

    # ── Project Provisioner ──────────────────────────────────

    def detect_project(self, path: Path) -> ProjectContext:
        stack = []
        if (path / "package.json").exists():
            stack.append("Node.js")
            try:
                pkg = json.loads((path / "package.json").read_text())
                deps = {**pkg.get("dependencies", {}), **pkg.get("devDependencies", {})}
                if "react" in deps:
                    stack.append("React")
                if "next" in deps:
                    stack.append("Next.js")
                if "typescript" in deps or (path / "tsconfig.json").exists():
                    stack.append("TypeScript")
            except Exception:
                pass

        if (path / "pyproject.toml").exists() or (path / "setup.py").exists():
            stack.append("Python")
            if (path / "pyproject.toml").exists():
                content = (path / "pyproject.toml").read_text()
                if "fastapi" in content.lower():
                    stack.append("FastAPI")
                if "django" in content.lower():
                    stack.append("Django")

        if (path / "go.mod").exists():
            stack.append("Go")
        if (path / "Cargo.toml").exists():
            stack.append("Rust")
        if (path / "Dockerfile").exists():
            stack.append("Docker")

        available_skills = [s.name for s in self.vault.list_global_skills()]

        return ProjectContext(
            path=str(path),
            name=path.name,
            has_git=(path / ".git").exists(),
            has_package_json=(path / "package.json").exists(),
            has_pyproject=(path / "pyproject.toml").exists(),
            # OpenCode-first
            has_agents_md=(path / "AGENTS.md").exists(),
            has_opencode_json=(path / "opencode.json").exists(),
            has_opencode_dir=(path / ".opencode").exists(),
            # Legacy compat
            has_claude_md=(path / "CLAUDE.md").exists(),
            has_gemini_json=(path / "gemini.json").exists(),
            has_nebula_agents=(path / ".nebula" / "agents").exists(),
            detected_stack=stack,
            available_skills=available_skills,
        )

    def plan_project_bootstrap(
        self,
        ctx: ProjectContext,
        selected_skills: list[str] | None = None,
    ) -> ProvisionPlan:
        entries: list[ProvisionEntry] = []
        project_path = Path(ctx.path)
        timestamp = datetime.now().strftime("%Y-%m-%d")
        stack_str = ", ".join(ctx.detected_stack) if ctx.detected_stack else "unknown"
        selected_skills = selected_skills or []
        cfg = self.vault.load()
        skills_subdir = cfg.project_skills_subdir   # e.g. ".opencode/skills"
        agents_subdir = cfg.project_agents_subdir   # e.g. ".opencode/agents"

        skill_injections = "\n".join(
            f"- `{s}` — see `{skills_subdir}/{s}/SKILL.md`" for s in selected_skills
        ) or "- (none injected yet)"

        # Core OpenCode directories
        for d in [".opencode", ".opencode/agents", ".opencode/skills", ".opencode/commands"]:
            entries.append(ProvisionEntry(
                path=str(project_path / d),
                content="",
                action="create",
                description=f"Create {d}/",
            ))

        # AGENTS.md (primary rules file for OpenCode)
        if not ctx.has_agents_md:
            entries.append(ProvisionEntry(
                path=str(project_path / "AGENTS.md"),
                content=AGENTS_MD_TEMPLATE.format(
                    timestamp=timestamp,
                    project_name=ctx.name,
                    project_path=ctx.path,
                    stack=stack_str,
                    skill_injections=skill_injections,
                ),
                action="create",
                description="AGENTS.md — OpenCode project rules & memory bank",
            ))

        # opencode.json (project config)
        if not ctx.has_opencode_json:
            entries.append(ProvisionEntry(
                path=str(project_path / "opencode.json"),
                content=OPENCODE_JSON_TEMPLATE,
                action="create",
                description="opencode.json — project-level OpenCode config",
            ))

        # Legacy compat: keep CLAUDE.md if it already exists, else skip
        # (don't create it fresh — AGENTS.md is the primary file)

        # Inject selected skills into configured project subdir
        for skill_name in selected_skills:
            src = self.vault.skills_dir / skill_name / "SKILL.md"
            dst_dir = project_path / skills_subdir / skill_name
            dst_file = dst_dir / "SKILL.md"
            if src.exists():
                entries.append(ProvisionEntry(
                    path=str(dst_dir), content="", action="create",
                    description=f"Skills dir: {skills_subdir}/{skill_name}/",
                ))
                entries.append(ProvisionEntry(
                    path=str(dst_file),
                    content=src.read_text(),
                    action="symlink",
                    description=f"Inject skill: {skill_name}",
                ))

        return ProvisionPlan(
            title=f"Bootstrap Project: {ctx.name}",
            entries=entries,
            total_files=sum(1 for e in entries if Path(e.path).suffix),
            total_dirs=sum(1 for e in entries if not Path(e.path).suffix),
            description=f"OpenCode-compatible bootstrap for {ctx.name}",
            project_path=ctx.path,
        )

    def execute_plan(
        self,
        plan: ProvisionPlan,
        on_progress: Optional[Callable[[str, float], None]] = None,
    ) -> tuple[bool, str]:
        """Execute a ProvisionPlan. Returns (success, message)."""
        try:
            total = max(len(plan.entries), 1)
            for i, entry in enumerate(plan.entries):
                p = Path(entry.path)
                if entry.action in ("create", "symlink"):
                    if p.suffix:  # file
                        p.parent.mkdir(parents=True, exist_ok=True)
                        p.write_text(entry.content, encoding="utf-8")
                    else:  # directory
                        p.mkdir(parents=True, exist_ok=True)
                elif entry.action == "modify":
                    if p.exists():
                        p.write_text(entry.content, encoding="utf-8")

                if on_progress:
                    on_progress(entry.description, (i + 1) / total)

            return True, f"✓ Provisioned {len(plan.entries)} entries successfully."
        except Exception as e:
            return False, f"✗ Provision failed: {e}"

    def install_plugin_to_project(
        self,
        project_path: Path,
        plugin_name: str,
        config_snippet: dict,
        scope: str = "project",  # "project" | "global"
    ) -> tuple[bool, str]:
        """Merge a plugin MCP entry into opencode.json (project or global)."""
        if scope == "global":
            target = Path.home() / ".config" / "opencode" / "opencode.json"
        else:
            target = project_path / "opencode.json"

        try:
            target.parent.mkdir(parents=True, exist_ok=True)
            if target.exists():
                try:
                    existing = json.loads(target.read_text())
                except Exception:
                    existing = {}
            else:
                existing = {
                    "$schema": "https://opencode.ai/config.json",
                    "mcp": {},
                }

            if "mcp" not in existing:
                existing["mcp"] = {}

            existing["mcp"][plugin_name] = config_snippet
            target.write_text(json.dumps(existing, indent=2), encoding="utf-8")
            return True, f"✓ Plugin '{plugin_name}' added to {target}"
        except Exception as e:
            return False, f"✗ Failed: {e}"

    def remove_plugin_from_project(
        self,
        project_path: Path,
        plugin_name: str,
        scope: str = "project",
    ) -> tuple[bool, str]:
        """Remove a plugin MCP entry from opencode.json."""
        if scope == "global":
            target = Path.home() / ".config" / "opencode" / "opencode.json"
        else:
            target = project_path / "opencode.json"
        try:
            if not target.exists():
                return False, "opencode.json not found"
            existing = json.loads(target.read_text())
            existing.get("mcp", {}).pop(plugin_name, None)
            target.write_text(json.dumps(existing, indent=2), encoding="utf-8")
            return True, f"✓ Plugin '{plugin_name}' removed"
        except Exception as e:
            return False, f"✗ Failed: {e}"

    def get_installed_plugins(self, project_path: Path, scope: str = "project") -> list[str]:
        """Return list of installed plugin names from opencode.json mcp section."""
        if scope == "global":
            target = Path.home() / ".config" / "opencode" / "opencode.json"
        else:
            target = project_path / "opencode.json"
        if not target.exists():
            return []
        try:
            return list(json.loads(target.read_text()).get("mcp", {}).keys())
        except Exception:
            return []

    # ── Blueprint Generator ──────────────────────────────────

    def generate_blueprint(
        self,
        template_id: str,
        variables: dict[str, str],
        project_name: str = "MyProject",
    ) -> str:
        ts = datetime.now().strftime("%Y-%m-%d %H:%M")
        generators = {
            "refactor": self._blueprint_refactor,
            "migration": self._blueprint_migration,
            "architecture": self._blueprint_architecture,
        }
        gen = generators.get(template_id, self._blueprint_refactor)
        return gen(variables, ts, project_name)

    def save_blueprint(self, content: str, name: str) -> Path:
        out = self.vault.blueprints_dir / f"{name}.md"
        out.write_text(content, encoding="utf-8")
        return out

    def _blueprint_refactor(self, v: dict, ts: str, proj: str) -> str:
        return f"""\
---
type: massive_refactor
project: {v.get('project', proj)}
target_module: {v.get('module', 'src/')}
generated: {ts}
thinking_mode: ultra
model_context: high_effort
preferred_model: {v.get('model', 'copilot/claude-opus-4-6')}
---

# Massive Refactor Blueprint
**Project:** {v.get('project', proj)}
**Target Module:** `{v.get('module', 'src/')}`
**Objective:** {v.get('objective', 'Improve code quality and maintainability')}

> [thinking_mode: ultra]
> [model_context: high_effort]
> Allocate maximum reasoning budget. This is a complex, multi-file refactor.

## Pre-Refactor Analysis

### Current State Assessment
- **Complexity:** {v.get('complexity', 'High')}
- **Test Coverage:** {v.get('coverage', 'Unknown')}
- **Known Issues:** {v.get('issues', 'See code comments')}

### Goals
1. {v.get('goal1', 'Improve readability')}
2. {v.get('goal2', 'Reduce coupling')}
3. {v.get('goal3', 'Improve test coverage')}

## Refactor Strategy

### Phase 1 — Audit (DO NOT MODIFY FILES)
- [ ] Read ALL files in `{v.get('module', 'src/')}`
- [ ] Map all dependencies and coupling points
- [ ] Identify patterns that need to change
- [ ] Produce dependency graph in comments

### Phase 2 — Test Safety Net
- [ ] Ensure existing tests pass: `{v.get('test_cmd', 'npm test')}`
- [ ] Add snapshot/integration tests for public APIs
- [ ] Confirm coverage baseline

### Phase 3 — Incremental Refactor
- [ ] Refactor one unit at a time — never batch large changes
- [ ] Run tests after every file change
- [ ] Commit with: `refactor(<scope>): <what changed>`

### Phase 4 — Validation
- [ ] All tests pass
- [ ] No regressions in `{v.get('critical_paths', 'core user flows')}`
- [ ] Performance benchmarks unchanged or improved

## Constraints
- **NEVER** change public API signatures without a deprecation path
- **NEVER** merge a phase that has failing tests
- **ALWAYS** prefer small, reviewable commits over large batches

## Success Criteria
{v.get('success', 'All tests pass. Code review approved. No performance regressions.')}
"""

    def _blueprint_migration(self, v: dict, ts: str, proj: str) -> str:
        return f"""\
---
type: legacy_migration
project: {v.get('project', proj)}
from_tech: {v.get('from_tech', 'Legacy System')}
to_tech: {v.get('to_tech', 'Modern Stack')}
generated: {ts}
thinking_mode: ultra
model_context: high_effort
preferred_model: {v.get('model', 'copilot/gemini-3.1-pro-preview')}
---

# Legacy Migration Blueprint
**From:** {v.get('from_tech', 'Legacy System')}
**To:** {v.get('to_tech', 'Modern Stack')}
**Timeline:** {v.get('timeline', 'TBD')}

> [thinking_mode: ultra]
> [model_context: high_effort]
> This is a high-stakes migration. Reason carefully before every step.

## Migration Strategy: Strangler Fig Pattern

### Step 1 — Inventory
- [ ] Document ALL entry points in `{v.get('from_tech', 'legacy')}`
- [ ] Map data flows end-to-end
- [ ] Identify high-risk areas: {v.get('risks', 'auth, data layer, integrations')}

### Step 2 — Parallel Run Setup
- [ ] Deploy new `{v.get('to_tech', 'modern')}` stack alongside legacy
- [ ] Set up feature flags for gradual traffic migration
- [ ] Implement data sync between old and new systems

### Step 3 — Migrate by Domain
| Domain | Priority | Status |
|--------|----------|--------|
| {v.get('domain1', 'Auth')} | P0 | ⬜ Not started |
| {v.get('domain2', 'API Layer')} | P1 | ⬜ Not started |
| {v.get('domain3', 'Data Layer')} | P2 | ⬜ Not started |

### Step 4 — Traffic Migration
- 5% → 25% → 50% → 100% gradual rollout
- Rollback trigger: error rate > {v.get('error_threshold', '1%')}

### Step 5 — Legacy Sunset
- [ ] Confirm 100% traffic on new system for {v.get('soak_period', '2 weeks')}
- [ ] Archive legacy codebase with git tag `legacy-sunset-YYYY-MM-DD`
- [ ] Remove legacy deployment infrastructure

## Rollback Plan
{v.get('rollback', 'Feature flags allow instant traffic reroute to legacy. Data sync is bidirectional until sunset.')}
"""

    def _blueprint_architecture(self, v: dict, ts: str, proj: str) -> str:
        return f"""\
---
type: system_design_architecture
project: {v.get('project', proj)}
scope: {v.get('scope', 'New System')}
generated: {ts}
thinking_mode: ultra
model_context: high_effort
preferred_model: {v.get('model', 'copilot/claude-opus-4-6')}
---

# System Design Architecture
**System:** {v.get('system_name', 'New System')}
**Scale Target:** {v.get('scale', 'TBD users/requests')}

> [thinking_mode: ultra]
> [model_context: high_effort]
> Produce complete, production-grade architecture. No hand-waving.

## Requirements

### Functional
1. {v.get('req1', 'Requirement 1')}
2. {v.get('req2', 'Requirement 2')}
3. {v.get('req3', 'Requirement 3')}

### Non-Functional
- **Availability:** {v.get('availability', '99.9% SLA')}
- **Latency:** {v.get('latency', 'p99 < 200ms')}
- **Scale:** {v.get('scale', '10k concurrent users')}
- **Security:** {v.get('security', 'SOC2 compliant')}

## C4 Architecture

### Level 1 — System Context
```
[User] → [{v.get('system_name', 'System')}] → [External APIs]
                    ↕
              [Database]
```

### Level 2 — Container
| Container | Tech | Responsibility |
|-----------|------|----------------|
| API Gateway | {v.get('api_tech', 'Kong / AWS API GW')} | Rate limit, auth, routing |
| App Service | {v.get('app_tech', 'Node.js / FastAPI')} | Business logic |
| Database | {v.get('db_tech', 'PostgreSQL')} | Persistent storage |
| Cache | {v.get('cache_tech', 'Redis')} | Session, hot data |
| Queue | {v.get('queue_tech', 'SQS / RabbitMQ')} | Async jobs |

## Data Model
```sql
-- Core entities for {v.get('system_name', 'System')}
-- TODO: Define schema
```

## API Design
- Style: {v.get('api_style', 'REST / GraphQL')}
- Auth: {v.get('auth', 'JWT + OAuth2')}
- Versioning: `/api/v1/`

## Infrastructure
- Cloud: {v.get('cloud', 'AWS / GCP')}
- IaC: Terraform
- CI/CD: GitHub Actions → {v.get('deploy_target', 'ECS / Cloud Run')}
- Monitoring: Datadog / Sentry

## ADRs
- ADR-001: {v.get('adr1', 'Why this database was chosen')}
- ADR-002: {v.get('adr2', 'Sync vs async processing decision')}

## Open Questions
- {v.get('question1', 'How do we handle eventual consistency?')}
- {v.get('question2', 'Sharding strategy for scale?')}
"""
